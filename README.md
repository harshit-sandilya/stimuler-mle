# PS Explaination

The problem was to design efficient ML systems for recommendation and analysis of user behaviour to help him learn a new language.

## Approach
The approach was at first usinf purely LLM based systems as we have no data in the initial stages. We use anthropic as it has some free limits and is easy to use. We also use anthropic for the initial stages of the project.
Moving on we use json holders to parse the data and extract the relevant information.
For more robustness we could do something like:

```python
try:
        agent = Agent(
            "openai:gpt-3.5-turbo",
            result_type=Union[TextHint, MultiHint],
            retries=5,
        )
        res = await agent.run(result)
        res = res.data
        if isinstance(res, TextHint):
            return HintResponse(hint_text=res.hint_text, hint_image=None)
        return HintResponse(hint_text=res.hint_text, hint_image=res.hint_image)
    except Exception:
        return HintResponse(
            hint_text=question.hints[question.hint_index], hint_image=None
        )
```

Once we have the data as given under `sample_data/`, we can use a combination of LLM embeddings and ML models as shown by using Google's T5 (a language model using ML with transformer embedding, transfer learning)
The LLM iteration is in `itr1.py`
The ML iteration is in `itr2.py`

## Results
Using a simple and lightweight embedding model based off of BERT, we were able to achieve an accuracy of 40% by just using around 47 examples.
The model chosen was decision tree as from experience tree based models were giving better results. Other models weren't tested due to time constarints.
For suggestion there was no accuracy, high probable reason being that the tokenizer is BPE (Byte Pair Encoding) which is not suitable for text generation. We could use a different tokenizer like WordPiece or SentencePiece.
ML models were chosen due to fast processing and accuracy. DL systems are compute intensive and would increase accuracy here.

## Recommendation
In recommendation engine we consider the minimal number of features, user age and location. For initial phases due to data limitation, LLM is also being used here.
After initial phase we could give:
- Sentence embeddings
- User feedback

The flow would be somewhat, User data (encoded, processed), User feedback, Flaw sentences encoding and the output would be a list of suggestion along the fixed question DB.
The drawback is that the model is not scalable and requires a lot of data to train. And there is no new question added except manually.
Final proposed solution is a combination of both methods, 3Q already existing and 2 new questions generated by LLM.
